{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df74b0e",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN) - This uses two neural networks namely generator and discriminator. In this project the goal is to train a GAN on the MNIST dataset (handwritten digits) to generate realistic images of digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d4beb",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "20ebb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbded6c2",
   "metadata": {},
   "source": [
    "# Load and preprocess MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "8eb7f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "x_train = (x_train - 127.5) / 127.5  \n",
    "x_train = np.expand_dims(x_train, axis=-1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85368c76",
   "metadata": {},
   "source": [
    "# Wasserstein loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "70de4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.keras.backend.mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty(discriminator, real_images, fake_images, batch_size):\n",
    "    \"\"\"Calculates the gradient penalty for WGAN-GP\"\"\"\n",
    "    alpha = tf.random.uniform((batch_size, 1, 1, 1), 0, 1, dtype=tf.float32)\n",
    "    real_images = tf.cast(real_images, tf.float32)  # Ensure correct data type\n",
    "    fake_images = tf.cast(fake_images, tf.float32)  # Ensure correct data type\n",
    "    interpolated = alpha * real_images + (1 - alpha) * fake_images\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated)\n",
    "        pred = discriminator(interpolated)\n",
    "    grads = tape.gradient(pred, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    penalty = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96b708",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "791d5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(100,)),\n",
    "        layers.Dense(7 * 7 * 128),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2D(1, kernel_size=7, activation=\"tanh\", padding=\"same\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf59d9",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "ab868e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d46dc",
   "metadata": {},
   "source": [
    "# Build generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "498ca5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85397a3",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "8633b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.5, beta_2=0.9)\n",
    "d_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.5, beta_2=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7ab03",
   "metadata": {},
   "source": [
    "# Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "51ae91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "batch_size = 64\n",
    "sample_interval = 1000\n",
    "lambda_gp = 10  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505ff99",
   "metadata": {},
   "source": [
    "# Training loop, discriminator, and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "d5e60cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    \n",
    "    # Train Discriminator\n",
    "    noise = tf.random.normal((batch_size, 100))\n",
    "    fake_images = generator(noise, training=True)\n",
    "\n",
    "    with tf.GradientTape() as d_tape:\n",
    "        real_pred = discriminator(real_images, training=True)\n",
    "        fake_pred = discriminator(fake_images, training=True)\n",
    "        gp = gradient_penalty(discriminator, real_images, fake_images, batch_size)\n",
    "        d_loss = tf.reduce_mean(fake_pred) - tf.reduce_mean(real_pred) + lambda_gp * gp\n",
    "\n",
    "    d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    d_optimizer.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "\n",
    "    # Train Generator\n",
    "    noise = tf.random.normal((batch_size, 100))\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        fake_images = generator(noise, training=True)\n",
    "        fake_pred = discriminator(fake_images, training=True)\n",
    "        g_loss = -tf.reduce_mean(fake_pred)\n",
    "\n",
    "    g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "\n",
    "    return d_loss, g_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6043d",
   "metadata": {},
   "source": [
    "# Save generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "44686e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def save_generated_images(epoch, n=3):\n",
    "    noise = np.random.normal(0, 1, (n * n, 100))\n",
    "    gen_imgs = generator.predict(noise, verbose=0)\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale from [-1,1] to [0,1]\n",
    "\n",
    "    fig, axs = plt.subplots(n, n, figsize=(6, 6))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            axs[i, j].imshow(gen_imgs[i * n + j, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show in notebook\n",
    "    plt.show()\n",
    "\n",
    "    # Save image to file\n",
    "    fig.savefig(f\"generated_epoch_{epoch}.png\")\n",
    "    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f926e8",
   "metadata": {},
   "source": [
    "# Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "124cef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(x_train):\n",
    "    for epoch in range(epochs):\n",
    "        # Get random batch of real images\n",
    "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "        real_images = x_train[idx]\n",
    "\n",
    "        # Train the GAN\n",
    "        d_loss, g_loss = train_step(real_images)\n",
    "\n",
    "        # Print progress\n",
    "        if epoch % sample_interval == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, [D loss: {d_loss:.4f}], [G loss: {g_loss:.4f}]\")\n",
    "            save_generated_images(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "13ae4696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c3b19",
   "metadata": {},
   "source": [
    "# Seeing [] means:\n",
    "\n",
    "# TensorFlow currently does NOT detect any GPU on my system. The training and image generation is running only on your CPU.\n",
    "\n",
    "# This is why my GAN is super slow. I will use Google Colab for training and image generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
